{"cells":[{"cell_type":"markdown","id":"e2a030e3","metadata":{"id":"e2a030e3"},"source":["# Hands-On Pertemuan 14: Advanced Machine Learning using Spark MLlib"]},{"cell_type":"markdown","id":"099562db","metadata":{"id":"099562db"},"source":["## Objectives:\n","- Understand and implement advanced machine learning tasks using Spark MLlib.\n","- Build and evaluate models using real-world datasets.\n","- Explore techniques like feature engineering and hyperparameter tuning.\n"]},{"cell_type":"markdown","id":"77df771a","metadata":{"id":"77df771a"},"source":["## Introduction to Spark MLlib\n","Spark MLlib is a scalable library for machine learning that integrates seamlessly with the Spark ecosystem. It supports a wide range of tasks, including regression, classification, clustering, and collaborative filtering."]},{"cell_type":"code","execution_count":null,"id":"d9ae225b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9ae225b","executionInfo":{"status":"ok","timestamp":1733651031997,"user_tz":-420,"elapsed":29113,"user":{"displayName":"Ferdi Maulana","userId":"10536097119351280338"}},"outputId":"9bcd46e0-a3ec-4c81-9aae-a4dff43190f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Coefficients: [0.9999999999999992]\n","Intercept: 15.000000000000009\n"]}],"source":["# Example: Linear Regression with Spark MLlib\n","from pyspark.sql import SparkSession\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.feature import VectorAssembler\n","\n","# Initialize Spark Session\n","spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n","\n","# Load sample data\n","data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n","columns = ['ID', 'Feature', 'Target']\n","df = spark.createDataFrame(data, columns)\n","\n","# Prepare data for modeling\n","assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n","df_transformed = assembler.transform(df)\n","\n","# Train a linear regression model\n","lr = LinearRegression(featuresCol='Features', labelCol='Target')\n","model = lr.fit(df_transformed)\n","\n","# Print model coefficients\n","print(f'Coefficients: {model.coefficients}')\n","print(f'Intercept: {model.intercept}')\n"]},{"cell_type":"code","source":["# Practice: Logistic Regression\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.sql.functions import col\n","\n","spark = SparkSession.builder.appName('MLlib Example2').getOrCreate()\n","\n","# Example dataset\n","data = [(1, [2.0, 3.0], 0), (2, [1.0, 5.0], 1), (3, [2.5, 4.5], 1), (4, [3.0, 6.0], 0)]\n","columns = ['ID', 'Features', 'Label']\n","df = spark.createDataFrame(data, columns)\n","\n","# Instead of using 'Features' directly, we need to access the elements within the array\n","# Create new columns for 'Features[0]' and 'Features[1]' using Spark functions\n","df = df.withColumn('Features0', col('Features').getItem(0)) \\\n","       .withColumn('Features1', col('Features').getItem(1))\n","\n","# Now use VectorAssembler with the new columns\n","assembler = VectorAssembler(inputCols=['Features0', 'Features1'], outputCol='FeaturesVector')\n","df = assembler.transform(df)\n","\n","# Train logistic regression model using the 'FeaturesVector' column\n","lr = LogisticRegression(featuresCol='FeaturesVector', labelCol='Label')\n","model = lr.fit(df)\n","\n","# Display coefficients and summary\n","print(f'Coefficients: {model.coefficients}')\n","print(f'Intercept: {model.intercept}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfvlj5v8hxi-","executionInfo":{"status":"ok","timestamp":1733666106712,"user_tz":-420,"elapsed":17217,"user":{"displayName":"Ferdi Maulana","userId":"10536097119351280338"}},"outputId":"234abe8e-145a-41f0-f13e-e4227a011f86"},"id":"rfvlj5v8hxi-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Coefficients: [-12.262057929180484,4.087352266486688]\n","Intercept: 11.56891272665312\n"]}]},{"cell_type":"code","execution_count":null,"id":"b9066e04","metadata":{"id":"b9066e04","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733669935211,"user_tz":-420,"elapsed":6815,"user":{"displayName":"Ferdi Maulana","userId":"10536097119351280338"}},"outputId":"1f4937b9-4f00-43f6-d0b0-6221cbd0318a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cluster Centers: [array([12.5, 12.5]), array([3., 3.])]\n","+---+------------+--------------+----------+\n","| ID|    Features|FeaturesVector|prediction|\n","+---+------------+--------------+----------+\n","|  1|  [1.0, 1.0]|     [1.0,1.0]|         1|\n","|  2|  [5.0, 5.0]|     [5.0,5.0]|         1|\n","|  3|[10.0, 10.0]|   [10.0,10.0]|         0|\n","|  4|[15.0, 15.0]|   [15.0,15.0]|         0|\n","+---+------------+--------------+----------+\n","\n"]}],"source":["# Practice: Kmeans Clustering\n","from pyspark.ml.clustering import KMeans\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.sql.functions import col\n","\n","# Initialize Spark session\n","spark = SparkSession.builder.appName('KMeans Example').getOrCreate()\n","\n","# Example dataset\n","data = [(1, [1.0, 1.0]), (2, [5.0, 5.0]), (3, [10.0, 10.0]), (4, [15.0, 15.0])]\n","columns = ['ID', 'Features']\n","df = spark.createDataFrame(data, columns)\n","\n","# Extract elements from 'Features' array into separate columns\n","df = df.withColumn('Features0', col('Features').getItem(0)) \\\n","       .withColumn('Features1', col('Features').getItem(1))\n","\n","# Use VectorAssembler with the new columns\n","assembler = VectorAssembler(inputCols=['Features0', 'Features1'], outputCol='FeaturesVector')\n","df_vector = assembler.transform(df)\n","\n","# Train KMeans clustering model using the 'FeaturesVector' column\n","kmeans = KMeans(featuresCol='FeaturesVector', k=2)\n","model = kmeans.fit(df_vector)\n","\n","# Show cluster centers\n","centers = model.clusterCenters()\n","print(f'Cluster Centers: {centers}')\n","\n","# Optionally, show the dataset with cluster assignments\n","df_clusters = model.transform(df_vector)\n","df_clusters.select('ID', 'Features', 'FeaturesVector', 'prediction').show()"]},{"cell_type":"markdown","id":"a60a8d7e","metadata":{"id":"a60a8d7e"},"source":["## Homework\n","- Load a real-world dataset into Spark and prepare it for machine learning tasks.\n","- Build a classification model using Spark MLlib and evaluate its performance.\n","- Explore hyperparameter tuning using cross-validation.\n"]},{"cell_type":"code","source":["# Import libraries\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler, StringIndexer\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","import pandas as pd\n","import requests\n","from io import StringIO\n","\n","# Initialize Spark session\n","spark = SparkSession.builder.appName('MLlib Homework').getOrCreate()\n","\n","# Load dataset\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n","columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n","\n","# Download the dataset\n","response = requests.get(url)\n","iris_data = pd.read_csv(StringIO(response.text), header=None, names=columns)\n","\n","# Create a Spark DataFrame from the pandas DataFrame\n","data = spark.createDataFrame(iris_data)\n","\n","# Inspect the data\n","data.show(5)\n","data.printSchema()\n","\n","# Data preparation\n","# Encode categorical target column (species) to numerical\n","indexer = StringIndexer(inputCol=\"species\", outputCol=\"label\")\n","data = indexer.fit(data).transform(data)\n","\n","# Assemble feature columns into a single vector\n","feature_cols = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n","assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n","data = assembler.transform(data)\n","\n","# Split the data into training and test sets\n","train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n","\n","# Build a classification model\n","lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n","\n","# Hyperparameter tuning with Cross-Validation\n","paramGrid = ParamGridBuilder() \\\n","    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n","    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n","    .build()\n","\n","# Define evaluator\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","\n","# Perform cross-validation\n","crossval = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n","cv_model = crossval.fit(train_data)\n","\n","# Evaluate the model on test data\n","predictions = cv_model.transform(test_data)\n","accuracy = evaluator.evaluate(predictions)\n","\n","# Show results\n","print(f\"Test Set Accuracy: {accuracy:.2f}\")\n","predictions.select(\"features\", \"label\", \"prediction\").show()\n","\n","# Best model hyperparameters\n","best_model = cv_model.bestModel\n","print(\"Best Model Parameters:\")\n","print(f\"  - regParam: {best_model._java_obj.getRegParam()}\")\n","print(f\"  - elasticNetParam: {best_model._java_obj.getElasticNetParam()}\")\n","\n","# Stop Spark session\n","spark.stop()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UGQpuqCe9oN0","executionInfo":{"status":"ok","timestamp":1733675222586,"user_tz":-420,"elapsed":121423,"user":{"displayName":"Ferdi Maulana","userId":"10536097119351280338"}},"outputId":"a316e3e8-3580-4ffd-c81c-cfe90f9dd1ee"},"id":"UGQpuqCe9oN0","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","+------------+-----------+------------+-----------+-----------+\n","|sepal_length|sepal_width|petal_length|petal_width|    species|\n","+------------+-----------+------------+-----------+-----------+\n","|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n","|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n","|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n","|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n","|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n","+------------+-----------+------------+-----------+-----------+\n","only showing top 5 rows\n","\n","root\n"," |-- sepal_length: double (nullable = true)\n"," |-- sepal_width: double (nullable = true)\n"," |-- petal_length: double (nullable = true)\n"," |-- petal_width: double (nullable = true)\n"," |-- species: string (nullable = true)\n","\n","Test Set Accuracy: 0.97\n","+-----------------+-----+----------+\n","|         features|label|prediction|\n","+-----------------+-----+----------+\n","|[4.4,3.0,1.3,0.2]|  0.0|       0.0|\n","|[4.6,3.2,1.4,0.2]|  0.0|       0.0|\n","|[4.6,3.6,1.0,0.2]|  0.0|       0.0|\n","|[4.8,3.1,1.6,0.2]|  0.0|       0.0|\n","|[4.9,3.1,1.5,0.1]|  0.0|       0.0|\n","|[5.0,3.2,1.2,0.2]|  0.0|       0.0|\n","|[5.0,3.6,1.4,0.2]|  0.0|       0.0|\n","|[5.1,3.8,1.5,0.3]|  0.0|       0.0|\n","|[5.4,3.7,1.5,0.2]|  0.0|       0.0|\n","|[5.4,3.9,1.3,0.4]|  0.0|       0.0|\n","|[5.4,3.9,1.7,0.4]|  0.0|       0.0|\n","|[5.5,3.5,1.3,0.2]|  0.0|       0.0|\n","|[5.6,2.5,3.9,1.1]|  1.0|       1.0|\n","|[5.7,3.8,1.7,0.3]|  0.0|       0.0|\n","|[6.1,2.8,4.0,1.3]|  1.0|       1.0|\n","|[6.4,3.2,4.5,1.5]|  1.0|       1.0|\n","|[4.9,2.5,4.5,1.7]|  2.0|       1.0|\n","|[5.5,2.4,3.8,1.1]|  1.0|       1.0|\n","|[5.5,2.5,4.0,1.3]|  1.0|       1.0|\n","|[5.7,2.9,4.2,1.3]|  1.0|       1.0|\n","+-----------------+-----+----------+\n","only showing top 20 rows\n","\n","Best Model Parameters:\n","  - regParam: 0.01\n","  - elasticNetParam: 0.5\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"10wHynocxxMZauHkKx-sc6hB-GsLWBjqm","timestamp":1733677396523}]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}